{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7d9f8f",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d08d96",
   "metadata": {},
   "source": [
    "## Starting the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4465582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.version 3.1.1\n",
      "sparknlp.version() 3.0.3\n",
      "sparkocr.version() 3.2.0\n",
      "sparknlp_jsl.version() 3.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "import sparkocr\n",
    "# Create or get Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "SECRET = os.environ[\"SECRET\"]\n",
    "JSL_VERSION = os.environ[\"JSL_VERSION\"]\n",
    "OCR_BASE_VERSION = os.environ[\"OCR_BASE_VERSION\"]\n",
    "OCR_SPARK_VERSION = os.environ[\"OCR_SPARK_VERSION\"]\n",
    "OCR_VERSION = f\"{OCR_BASE_VERSION}-{OCR_SPARK_VERSION}\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\",\"12G\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"800M\")\\\n",
    "    .config(\"spark.sql.legacy.allowUntypedScalaUDF\", \"true\") \\\n",
    "    .config(\"spark.jars.packages\", f\"com.johnsnowlabs.nlp:spark-nlp_2.12:{JSL_VERSION}\") \\\n",
    "    .config(\"spark.jars\", f\"file:///jars/spark-nlp-jsl-{JSL_VERSION}.jar,file:///jars/spark-ocr-assembly-{OCR_VERSION}.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"spark.version\", spark.version)\n",
    "print(\"sparknlp.version()\", sparknlp.version())\n",
    "print(\"sparkocr.version()\", sparkocr.version())\n",
    "print(\"sparknlp_jsl.version()\", sparknlp_jsl.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8acb7",
   "metadata": {},
   "source": [
    "# Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68f1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3662d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognize_entities_dl download started this may take some time.\n",
      "Approx size to download 160.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entities': ['Harry Potter'],\n",
       " 'document': ['Harry Potter is a great movie'],\n",
       " 'token': ['Harry', 'Potter', 'is', 'a', 'great', 'movie'],\n",
       " 'ner': ['B-PER', 'I-PER', 'O', 'O', 'O', 'O'],\n",
       " 'embeddings': ['Harry', 'Potter', 'is', 'a', 'great', 'movie'],\n",
       " 'sentence': ['Harry Potter is a great movie']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('recognize_entities_dl', 'en')\n",
    "result = pipeline.annotate(\"Harry Potter is a great movie\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284991da",
   "metadata": {},
   "source": [
    "# Spark NLP for Healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bdb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93bf5096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 363.9 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "\n",
    "#sentenceDetector = SentenceDetector()\\\n",
    "        #.setInputCols([\"document\"])\\\n",
    "        #.setOutputCol(\"sentence\")\n",
    "sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    " \n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\")\\\n",
    "        .setInputCols([\"sentence\",\"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = MedicalNerModel.pretrained(\"ner_clinical_large\",\"en\",\"clinical/models\")\\\n",
    "        .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "        .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter])\n",
    "\n",
    "\n",
    "data = spark.createDataFrame([[\"\"\"The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family. Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population. The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons separated byapproximately 2.2 and approximately 2.6 kb introns, respectively. We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair (bp) insertion/deletion. Ourexpression studies revealed the presence of the transcript in various humantissues including pancreas, and two major insulin-responsive tissues: fat andskeletal muscle. The characterization of the KCNJ9 gene should facilitate furtherstudies on the function of the KCNJ9 protein and allow evaluation of thepotential role of the locus in Type II diabetes.\"\n",
    "\"\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(data)\n",
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a56bd597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                            result|                                          metadata|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|the G-protein-activated inwardly rectifying pot...|{entity -> TREATMENT, sentence -> 0, chunk -> 0...|\n",
      "|                           the genomicorganization|{entity -> TREATMENT, sentence -> 1, chunk -> 1...|\n",
      "|     a candidate gene forType II diabetes mellitus|{entity -> PROBLEM, sentence -> 1, chunk -> 2, ...|\n",
      "|                                   byapproximately|{entity -> TREATMENT, sentence -> 2, chunk -> 3...|\n",
      "|                   single nucleotide polymorphisms|{entity -> TREATMENT, sentence -> 3, chunk -> 4...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.selectExpr(\"explode(ner_chunk) as result\") \\\n",
    "    .select(\"result.result\", \"result.metadata\") \\\n",
    "    .show(5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bbd1c7",
   "metadata": {},
   "source": [
    "# Spark OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a385f309",
   "metadata": {
    "id": "Kj8tsYfljiBP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-18 16:46:48--  http://www.asx.com.au/asxpdf/20171103/pdf/43nyyw9r820c6r.pdf\n",
      "Resolving www.asx.com.au (www.asx.com.au)... 203.15.147.66\n",
      "Connecting to www.asx.com.au (www.asx.com.au)|203.15.147.66|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://www.asx.com.au/asxpdf/20171103/pdf/43nyyw9r820c6r.pdf [following]\n",
      "--2021-06-18 16:46:49--  https://www.asx.com.au/asxpdf/20171103/pdf/43nyyw9r820c6r.pdf\n",
      "Connecting to www.asx.com.au (www.asx.com.au)|203.15.147.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 212973 (208K) [application/pdf]\n",
      "Saving to: 'sample_doc.pdf'\n",
      "\n",
      "sample_doc.pdf      100%[===================>] 207.98K   215KB/s    in 1.0s    \n",
      "\n",
      "2021-06-18 16:46:51 (215 KB/s) - 'sample_doc.pdf' saved [212973/212973]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -L \"http://www.asx.com.au/asxpdf/20171103/pdf/43nyyw9r820c6r.pdf\" -O sample_doc.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acdbe44",
   "metadata": {
    "id": "FwAGTafIj4Bi"
   },
   "outputs": [],
   "source": [
    "from sparkocr.transformers import *\n",
    "from sparkocr.transformers import *\n",
    "from pyspark.ml import PipelineModel\n",
    "from sparkocr.utils import display_image\n",
    "from sparkocr.metrics import score\n",
    "def pipeline():\n",
    "    # Transforrm PDF document to images per page\n",
    "    pdf_to_image = PdfToImage()\\\n",
    "          .setInputCol(\"content\")\\\n",
    "          .setOutputCol(\"image\")\n",
    "    # Run OCR\n",
    "    ocr = ImageToText()\\\n",
    "          .setInputCol(\"image\")\\\n",
    "          .setOutputCol(\"text\")\\\n",
    "          .setConfidenceThreshold(65)\n",
    "    \n",
    "    pipeline = PipelineModel(stages=[\n",
    "        pdf_to_image,\n",
    "        ocr\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c18811cc",
   "metadata": {
    "id": "xNh4i1Woj6oo"
   },
   "outputs": [],
   "source": [
    "pdf = 'sample_doc.pdf'\n",
    "pdf_example_df = spark.read.format(\"binaryFile\").load(pdf).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6f6103",
   "metadata": {
    "id": "Tp7a9yMqkCGu"
   },
   "outputs": [],
   "source": [
    "result = pipeline().transform(pdf_example_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e492db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22587,
     "status": "ok",
     "timestamp": 1618325351009,
     "user": {
      "displayName": "muhammet şantaş",
      "photoUrl": "",
      "userId": "01037434825541536598"
     },
     "user_tz": -180
    },
    "id": "VWND8q95kE47",
    "outputId": "dd581f75-4a9d-4375-d1e9-a9d5a57eb44c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----------------+\n",
      "|pagenum|                text|       confidence|\n",
      "+-------+--------------------+-----------------+\n",
      "|      0|ASX ANNOUNCEMENT\n",
      "...|91.79221683078342|\n",
      "+-------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"pagenum\",\"text\", \"confidence\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493c3696",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22573,
     "status": "ok",
     "timestamp": 1618325351010,
     "user": {
      "displayName": "muhammet şantaş",
      "photoUrl": "",
      "userId": "01037434825541536598"
     },
     "user_tz": -180
    },
    "id": "rj7rv4b7kTNo",
    "outputId": "83822c91-9132-4d91-955f-c298c3c5a98f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='ASX ANNOUNCEMENT\\n3 November 2017\\n\\nNotice Pursuant to Paragraph 708A(5)(e) of the Corporations Act\\n2001 (\"Act\")\\n\\nDigitalX Limited (ASX:DCC) (DCC or the Company) confirms that the Company has today\\nissued 620,000 Fully Paid Ordinary Shares (Shares) upon exercise of 620,000 Unlisted\\nOptions exercisable at $0.0324 Expiring 14 September 2019 and 3,725,000 Shares upon\\nexercise of 3,725,000 Unlisted Incentive Options exercisable at $0.08 expiring 10 February\\n2018.\\n\\nThe Act restricts the on-sale of securities issued without disclosure, unless the sale is exempt\\nunder section 708 or 708A of the Act. By giving this notice, a sale of the Shares noted above\\nwill fall within the exemption in section 708A(5) of the Act.\\n\\nThe Company hereby notifies ASX under paragraph 708A(5)(e) of the Act that:\\n(a) the Company issued the Shares without disclosure to investors under Part 6D.2 of\\nthe Act;\\n(b) as at the date of this notice, the Company has complied with the provisions of Chapter\\n2M of the Act as they apply to the Company, and section 674 of the Act; and\\n(c) as at the date of this notice, there is no information:\\na. — that has been excluded from a continuous disclosure notice in accordance with\\nthe ASX Listing Rules; and\\nb. — that investors and their professional advisers would reasonably require for the\\npurpose of making an informed assessment of:\\ni. the assets and liabilities, financial position and performance, profits and\\nlosses and prospects of the Company; or\\nii. the rights and liabilities attaching to the relevant Shares.\\n\\nDigitalX Limited\\n\\nLeigh Travers\\nChief Executive Officer\\nT: +61 439 376 847\\n\\nAbout DigitalX\\n\\nDigitalX is a Blockchain technology Company with offices in Perth and New York. DigitalX\\nprovides Blockchain consulting services, ICO advisory services and software development.\\nPartners can use DigitalX’s technology expertise to deliver innovative products to global\\nmarkets.\\n')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select(\"text\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ee403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
